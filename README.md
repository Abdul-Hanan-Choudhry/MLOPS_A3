# NASA APOD MLOps Pipeline

An automated data pipeline using Apache Airflow to fetch NASA's Astronomy Picture of the Day (APOD), with MLOps practices including data versioning with DVC.

## ğŸš€ Features

- **Data Extraction**: Fetches NASA APOD data daily via API
- **Data Storage**: 
  - Images saved to local storage
  - Metadata stored in PostgreSQL database
  - CSV export for data versioning
- **Data Versioning**: DVC tracks changes to dataset
- **Orchestration**: Airflow DAG with task dependencies
- **Code Versioning**: Git/GitHub for pipeline code

## ğŸ“ Project Structure

```
MLops3/
â”œâ”€â”€ dags/
â”‚   â””â”€â”€ nasa_apod_dag.py          # Main Airflow DAG
â”œâ”€â”€ include/
â”‚   â”œâ”€â”€ apod_data.csv              # NASA APOD metadata
â”‚   â”œâ”€â”€ apod_data.csv.dvc          # DVC tracking file
â”‚   â”œâ”€â”€ .dvc/                      # DVC configuration
â”‚   â””â”€â”€ images/                    # Downloaded images
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ dags/
â”‚       â””â”€â”€ test_dag_example.py    # DAG validation tests
â”œâ”€â”€ Dockerfile                     # Container definition
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ docker-compose.override.yml    # Docker compose overrides
â””â”€â”€ .env                          # Environment variables
```

## ğŸ› ï¸ Setup & Installation

### Prerequisites
- Docker Desktop
- Astro CLI (`winget install -e --id Astronomer.Astro`)
- Git

### Installation Steps

1. **Clone the repository**
```bash
git clone https://github.com/Abdul-Hanan-Choudhry/MLOPS_A3.git
cd MLOPS_A3
```

2. **Start Airflow**
```bash
astro dev start
```

3. **Access Airflow UI**
- URL: `http://localhost:8081`
- Username: `admin`
- Password: `admin`

## ğŸ”§ Configuration

### Environment Variables (.env)
```env
nasa_api_key=YOUR_NASA_API_KEY
POSTGRES_HOST=postgres
POSTGRES_PORT=5432
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
POSTGRES_DB=postgres
```

### Database
- **Host**: postgres (internal) / localhost:5433 (external)
- **Database**: airflow
- **Table**: apod_data

## ğŸ“Š DAG Details

**DAG ID**: `nasa_apod_pipeline`

**Schedule**: Daily (`@daily`)

**Tasks**:
1. `fetch_nasa_apod` - Fetches data from NASA API, saves image and CSV
2. `version_with_dvc` - Tracks CSV changes with DVC

**Tags**: `["nasa", "etl", "mlops"]`

**Retries**: 2

## ğŸ—‚ï¸ Data Versioning with DVC

The project uses DVC to version the APOD dataset:

```bash
# Pull latest data
dvc pull

# Check data status
dvc status

# View data changes
git log include/apod_data.csv.dvc
```

## ğŸ§ª Testing

Run DAG validation tests:
```bash
astro dev pytest
```

Tests verify:
- No import errors
- Required tags present
- Retry configuration

## ğŸ“¦ Dependencies

- **requests**: HTTP API calls
- **pandas**: Data manipulation
- **psycopg2-binary**: PostgreSQL connectivity
- **dvc**: Data version control
- **python-dotenv**: Environment variable management

## ğŸ¯ Pipeline Flow

```
NASA API â†’ Fetch Data â†’ Save Image â†’ Save CSV â†’ Save to Postgres â†’ DVC Versioning
```

## ğŸ“¸ Sample Output

The pipeline generates:
- **Images**: `/include/images/[title].jpg`
- **CSV**: `/include/apod_data.csv`
- **Database**: `apod_data` table in Postgres

## ğŸ¤ Contributing

This is an academic project for MLOps coursework.

## ğŸ“„ License

Educational use only.

## ğŸ‘¤ Author

Abdul Hanan Choudhry

## ğŸ”— Links

- **GitHub Repository**: https://github.com/Abdul-Hanan-Choudhry/MLOPS_A3.git
- **NASA APOD API**: https://api.nasa.gov/
```